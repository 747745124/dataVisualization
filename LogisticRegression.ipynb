{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## é€»è¾‘å›å½’å®ŒæˆäºŒåˆ†ç±»ï¼Œåˆ©ç”¨sklearnåº“å®Œæˆtokenize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ItemID  label                                              tweet\n",
       "0       1      0                       is so sad for my APL frie...\n",
       "1       2      0                     I missed the New Moon trail...\n",
       "2       3      1                            omg its already 7:30 :O\n",
       "3       4      0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5      0           i think mi bf is cheating on me!!!   ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemID</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>is so sad for my APL frie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>I missed the New Moon trail...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>omg its already 7:30 :O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>i think mi bf is cheating on me!!!   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import re\n",
    "#æ•°æ®æ¥æºKaggle https://www.kaggle.com/imrandude/twitter-sentiment-analysis/notebooks\n",
    "#å…±10ä¸‡æ¡ \n",
    "df = pd.read_csv('train.csv',encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## æ•°æ®æ¸…æ´—\n",
    "* éœ€è¦å®Œæˆåˆ é™¤æ ‡ç‚¹ç¬¦å·\n",
    "* åˆ é™¤atç”¨æˆ·å†…å®¹ï¼ˆé‡‡ç”¨tweet-preprocessoråº“ï¼‰\n",
    "* ç»Ÿä¸€è½¬å°å†™"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tweet-preprocessor to clean tweets\n",
    "from string import punctuation\n",
    "import preprocessor as p\n",
    "for i in range(0,len(df)):\n",
    "    df['tweet'][i] = p.clean(df['tweet'][i])\n",
    "    df['tweet'][i] = ''.join([c for c in df['tweet'][i] if c not in punctuation])\n",
    "    df['tweet'][i] = df['tweet'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ItemID  label                                              tweet\n",
       "99984   99996      0  cupcake seems like a repeating problem hope yo...\n",
       "99985   99997      1  cupcake arrrr we both replied to each other ov...\n",
       "99986   99998      0                        cupcake2120 ya i thought so\n",
       "99987   99999      1  cupcakedollie yes yes im glad you had more fun...\n",
       "99988  100000      1                       cupcakekayla haha yes you do"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemID</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99984</th>\n      <td>99996</td>\n      <td>0</td>\n      <td>cupcake seems like a repeating problem hope yo...</td>\n    </tr>\n    <tr>\n      <th>99985</th>\n      <td>99997</td>\n      <td>1</td>\n      <td>cupcake arrrr we both replied to each other ov...</td>\n    </tr>\n    <tr>\n      <th>99986</th>\n      <td>99998</td>\n      <td>0</td>\n      <td>cupcake2120 ya i thought so</td>\n    </tr>\n    <tr>\n      <th>99987</th>\n      <td>99999</td>\n      <td>1</td>\n      <td>cupcakedollie yes yes im glad you had more fun...</td>\n    </tr>\n    <tr>\n      <th>99988</th>\n      <td>100000</td>\n      <td>1</td>\n      <td>cupcakekayla haha yes you do</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ•°æ®é›†åˆ’åˆ†\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['tweet'], df['label'], test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression to classify\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "predicted = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification report for classifier LogisticRegression():\n              precision    recall  f1-score   support\n\n           0       0.73      0.68      0.70     12287\n           1       0.79      0.82      0.80     17710\n\n    accuracy                           0.77     29997\n   macro avg       0.76      0.75      0.75     29997\nweighted avg       0.76      0.77      0.76     29997\n\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (lr, classification_report(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLrModel():\n",
    "    df = pd.read_csv('train.csv')\n",
    "    df.head()\n",
    "\n",
    "    for i in range(0,len(df)):\n",
    "        df['tweet'][i] = p.clean(df['tweet'][i])\n",
    "        df['tweet'][i] = ''.join([c for c in df['tweet'][i] if c not in punctuation])\n",
    "        df['tweet'][i] = df['tweet'][i].lower()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['tweet'], df['label'], test_size=0.3, shuffle=False)\n",
    "\n",
    "    vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "\n",
    "    return [vectorizer,lr]"
   ]
  },
  {
   "source": [
    "## å¯¹äºçˆ¬è™«æ•°æ®é›†è¿›è¡Œå¤„ç†"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id      conversation_id               created_at  \\\n",
       "0  1344795464877699076  1344793464127578112  2021-01-01 07:59:58 CST   \n",
       "1  1344795454987493376  1344795454987493376  2021-01-01 07:59:56 CST   \n",
       "2  1344795428596936705  1344795428596936705  2021-01-01 07:59:49 CST   \n",
       "3  1344795409550614529  1344795409550614529  2021-01-01 07:59:45 CST   \n",
       "4  1344795404538359811  1344795404538359811  2021-01-01 07:59:44 CST   \n",
       "\n",
       "         date      time  timezone              user_id         username  \\\n",
       "0  2021-01-01  07:59:58       800             20734655        urbanfoxe   \n",
       "1  2021-01-01  07:59:56       800   913589759544401920  stephthacreator   \n",
       "2  2021-01-01  07:59:49       800             15359416       nellbryden   \n",
       "3  2021-01-01  07:59:45       800  1253813929039597569   slowstrokeking   \n",
       "4  2021-01-01  07:59:44       800             50706690            511ny   \n",
       "\n",
       "                   name                                              place  \\\n",
       "0            Jenny Foxe                                                NaN   \n",
       "1               Stephhh                                                NaN   \n",
       "2           Nell Bryden                                                NaN   \n",
       "3  HOUSTON TX jan 22-25                                                NaN   \n",
       "4          511 New York  {'type': 'Point', 'coordinates': [40.750046, -...   \n",
       "\n",
       "   ...                    geo source user_rt_id user_rt retweet_id  \\\n",
       "0  ...  40.75773,-73.9857,5km    NaN        NaN     NaN        NaN   \n",
       "1  ...  40.75773,-73.9857,5km    NaN        NaN     NaN        NaN   \n",
       "2  ...  40.75773,-73.9857,5km    NaN        NaN     NaN        NaN   \n",
       "3  ...  40.75773,-73.9857,5km    NaN        NaN     NaN        NaN   \n",
       "4  ...  40.75773,-73.9857,5km    NaN        NaN     NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0  [{'screen_name': 'peterc83', 'name': 'Peter', ...           NaN        NaN   \n",
       "1                                                 []           NaN        NaN   \n",
       "2                                                 []           NaN        NaN   \n",
       "3                                                 []           NaN        NaN   \n",
       "4                                                 []           NaN        NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>conversation_id</th>\n      <th>created_at</th>\n      <th>date</th>\n      <th>time</th>\n      <th>timezone</th>\n      <th>user_id</th>\n      <th>username</th>\n      <th>name</th>\n      <th>place</th>\n      <th>...</th>\n      <th>geo</th>\n      <th>source</th>\n      <th>user_rt_id</th>\n      <th>user_rt</th>\n      <th>retweet_id</th>\n      <th>reply_to</th>\n      <th>retweet_date</th>\n      <th>translate</th>\n      <th>trans_src</th>\n      <th>trans_dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1344795464877699076</td>\n      <td>1344793464127578112</td>\n      <td>2021-01-01 07:59:58 CST</td>\n      <td>2021-01-01</td>\n      <td>07:59:58</td>\n      <td>800</td>\n      <td>20734655</td>\n      <td>urbanfoxe</td>\n      <td>Jenny Foxe</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,5km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{'screen_name': 'peterc83', 'name': 'Peter', ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1344795454987493376</td>\n      <td>1344795454987493376</td>\n      <td>2021-01-01 07:59:56 CST</td>\n      <td>2021-01-01</td>\n      <td>07:59:56</td>\n      <td>800</td>\n      <td>913589759544401920</td>\n      <td>stephthacreator</td>\n      <td>Stephhh</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,5km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1344795428596936705</td>\n      <td>1344795428596936705</td>\n      <td>2021-01-01 07:59:49 CST</td>\n      <td>2021-01-01</td>\n      <td>07:59:49</td>\n      <td>800</td>\n      <td>15359416</td>\n      <td>nellbryden</td>\n      <td>Nell Bryden</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,5km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1344795409550614529</td>\n      <td>1344795409550614529</td>\n      <td>2021-01-01 07:59:45 CST</td>\n      <td>2021-01-01</td>\n      <td>07:59:45</td>\n      <td>800</td>\n      <td>1253813929039597569</td>\n      <td>slowstrokeking</td>\n      <td>HOUSTON TX jan 22-25</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,5km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1344795404538359811</td>\n      <td>1344795404538359811</td>\n      <td>2021-01-01 07:59:44 CST</td>\n      <td>2021-01-01</td>\n      <td>07:59:44</td>\n      <td>800</td>\n      <td>50706690</td>\n      <td>511ny</td>\n      <td>511 New York</td>\n      <td>{'type': 'Point', 'coordinates': [40.750046, -...</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,5km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "nyc = pd.read_csv('NewYork01.csv')\n",
    "nyc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import preprocessor as p\n",
    "for i in range(0,len(nyc)):\n",
    "    nyc['tweet'][i] = p.clean(nyc['tweet'][i])\n",
    "    nyc['tweet'][i] = ''.join([c for c in nyc['tweet'][i] if c not in punctuation])\n",
    "    nyc['tweet'][i] = nyc['tweet'][i].lower()\n",
    "   \n",
    "vec,lrModel = getLrModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = vec.transform(nyc['tweet'])\n",
    "predict = lrModel.predict(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "no no no this cant be real lmao rt i cannot breathe\nnew opp pack in the air nigga this gas or what capitol at washington dc\nanother soccer lover reposted from times square new york city\nacabou de publicar uma foto em times square new york city\ncleared incident on nb at sts rockefeller ctr\ncleared incident on at sts rockefeller ctr\ncleared incident on at sts rockefeller ctr\ncleared incident on nb at sts rockefeller ctr\nim at in new york ny\nim at tomiz in new york ny\nim at stk steakhouse midtown nyc in new york ny\nim at modern szechuan in new york ny\nim at the red flame in new york ny\nim at hippodrome in new york ny\ncabin pressure beat milky way galaxy\nincident on at sts rockefeller ctr\nincident on nb at sts rockefeller ctr\ntoyota rav4 driver y104060c blocked the crosswalk near th ave on january and has been reported to this is in manhattan community board amp\ncleared incident on sb at st port authority bus terminal\ncleared incident on sb at st port authority bus terminal\nincident on sb at st port authority bus terminal\nno topps chrome in stock currently sorry about that\nmy new project drops features from and will be available on all digital streaming platforms including warner music group\nwere kicking off the new year with off on cards for the month of january some exclusions apply offer cannot be combined with other promotions or applied to previous purchases\nnew comics day picked up shouts to\n606 2279\n"
     ]
    }
   ],
   "source": [
    "for i in range(200,300):\n",
    "    if(predict[i]==0):\n",
    "        print(nyc['tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "606 2279\n"
     ]
    }
   ],
   "source": [
    "cnt0=0#negative\n",
    "cnt1=0#positive\n",
    "for i in range(0,len(nyc)):\n",
    "    if(predict[i]==0):\n",
    "        cnt0+=1\n",
    "    else:\n",
    "        cnt1+=1\n",
    "print(cnt0,cnt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "from string import punctuation\n",
    "import preprocessor as p\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "\n",
    "def getLrModel():\n",
    "    df = pd.read_csv('train.csv')\n",
    "    df.head()\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        df['tweet'][i] = p.clean(df['tweet'][i])\n",
    "        df['tweet'][i] = ''.join(\n",
    "            [c for c in df['tweet'][i] if c not in punctuation])\n",
    "        df['tweet'][i] = df['tweet'][i].lower()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['tweet'], df['label'], test_size=0.3, shuffle=False)\n",
    "\n",
    "    vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    joblib.dump(lr, 'saved_model/lr.pkl')\n",
    "    joblib.dump(vectorizer, 'saved_model/vec.pkl')\n",
    "    return [vectorizer, lr]\n",
    "\n",
    "\n",
    "def preprocess(fileName):\n",
    "    nyc = pd.read_csv(fileName)\n",
    "    for i in range(0, len(nyc)):\n",
    "        nyc['tweet'][i] = p.clean(nyc['tweet'][i])\n",
    "        nyc['tweet'][i] = ''.join(\n",
    "            [c for c in nyc['tweet'][i] if c not in punctuation])\n",
    "        nyc['tweet'][i] = nyc['tweet'][i].lower()\n",
    "    return nyc\n",
    "\n",
    "\n",
    "def predict(dataFrame, vec, lrModel):\n",
    "    nyc = dataFrame\n",
    "    tweet = vec.transform(nyc['tweet'])\n",
    "    predict = lrModel.predict(tweet)\n",
    "    cnt0 = 0  # negative\n",
    "    cnt1 = 0  # positive\n",
    "    for i in range(0, len(nyc)):\n",
    "        if(predict[i] == 0):\n",
    "            cnt0 += 1\n",
    "        else:\n",
    "            cnt1 += 1\n",
    "    print(cnt0, cnt1)\n",
    "    print(cnt0/(len(nyc)+1), cnt1/(len(nyc)+1))\n",
    "    return [predict, cnt0, cnt1]\n",
    "\n",
    "\n",
    "def allInOne(fileName):\n",
    "    nyc = preprocess(fileName)\n",
    "    lrModel = joblib.load('saved_model/lr.pkl')\n",
    "    vec = joblib.load('saved_model/vec.pkl')\n",
    "    result = predict(nyc, vec, lrModel)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ing at that map and it gets uncomfortable. Very quickly. lol\n",
      "@Kofie @ASPCA He good\n",
      "@kim_hoyos please\n",
      "@mrsrkfj What is this life?!?!\n",
      "@kim_hoyos just @ me next time\n",
      "@DankwaBrooks Oh ok\n",
      "@Kofie You started it!\n",
      "@Kofie Iâ€™ll feed him a Kof-a-loaf\n",
      "@yours0ftblood RIGHT LMAOOO like u took the time to give three stars SPECIFICALLY? you thought people would need this information? also â€œthis place looks awesome at nightâ€ great thank you for the heads up :)\n",
      "The wages of sin..\n",
      "me: i love open world RPGs where my choices MATTER   also me: thank god for this gamefaqs entry that breaks down in meticulous detail the consequences of all of my potential choices\n",
      "@ianofspencer That's sweeter\n",
      "My husband and I are spending the first night of 2020 rewatching Scream\n",
      "@dan_munz @mikekruger 3 means you could have 3 people sitting uncomfortably close to you. That gives 5 an advantage imo (4 is def most desireable.)\n",
      "@SuziSteffen Thank you! Glad the movie connected with you â¤ï¸\n",
      "@SincerelyBlogg @people Lord.\n",
      "@michelledeidre @RoseParade â¤ï¸â¤ï¸â¤ï¸â¤ï¸\n",
      "@BoneyStarks Correct\n",
      "@anna01930 ğŸ˜‰\n",
      "someone else replied â€œthe other review was right, smells like fartsâ€ like people really just drive past and say this shit\n",
      "@n_vpatel Now you're all grown up.\n",
      "@BieglerTom Youâ€™re making my point about how bad the wildfires are.\n",
      "@srothbell Thatâ€™s all the stuff Iâ€™m doing in 2021\n",
      "@MollyJongFast Cool that the paper of record gave him a ton of free publicity today.\n",
      "Halfway through my You Season 2 binge and I think... a meme just spoiled it for me?? ğŸ¤¬ #YouNetflix\n",
      "gus fring acts exactly like gus fring in the mandalorian\n",
      "@erikaharwood hi\n",
      "@reelsistas Seriously!\n",
      "â€œHey dadâ€ but â€œdadâ€ is Jay-Z\n",
      "@McBaine146 @noonanjo She could have definitely done cool career stuff after that\n",
      "@Journeys_Film ğŸ‘€ğŸ‘€ğŸ‘€\n",
      "@WriteinBK Yesssss\n",
      "@CybelDP Omg you survived!\n",
      "@BluePhoenix1 Lol yup!\n",
      "@RustenHurd Hahaha I was just saying she had a lot to lose! Sheâ€™d accomplished so much\n",
      "@bariweiss @nytopinion Thank you. Lead on!\n",
      "@Kehlani â¤ï¸â¤ï¸â¤ï¸ praying for you!\n",
      "@InHollywoodland A whole mess\n",
      "@InHollywoodland Yes\n",
      "Can you imagine if you woke up every day and BeyoncÃ© was your mom?\n",
      "I still canâ€™t believe Padme, a senator, gave up her life and career to be with a creepy volatile Justin Bieber-lite Jedi-in-training\n",
      "\"people get catfished off them filters. Not me, but I know people who have\"- Dennis Smith Jr  Lmao\n",
      "@marksbirch It is feeling that way. May need to pivot back into lifeguarding.\n",
      "Just got to see 30 of FDNY's finest storm my building while I was in the lobby thanks to a family leaving plastic in their oven. Happy New Year.\n",
      "@ELGINDOTCOM Nothing compares to that Chicago Bulls game at the Garden\n",
      "@LolaVicious FRFR\n",
      "@JJohnsonLaw @NBCNews Sheâ€™d be great! But I think someone new and not run through the primary is more likely.\n",
      "@cjsabbagh1 @ssscorvus I love that movie\n",
      "@cjsabbagh1 @ssscorvus I loved the first movie tho\n",
      "@cjsabbagh1 I remember asking this same question at the time of the first movie. Lots of people wrote about very good articles exploring that\n",
      "watching a show on Netflix, thought one of the actors looked vaguely handsome and familiar, turned out to be @maxjenkinsyall on DEAD TO ME.\n",
      "@tiffmoustakas @DohaMadani choosing the right running mate is crucial for 2020.\n",
      "@MegaMuto I see it!\n",
      "@twodigitz23 @CNN Dude I literally said this is exactly how it should be done. I applauded this person!\n",
      "i swear my mother revenge-programmed this with a â€œmelodramaâ€ option. like stuck on cliff? in a brooklyn studio? ok roomba\n",
      "@theferocity FACTS.\n",
      "@gabrielroth I am 7â€2 and 4 is still the best for (anti)social reasons\n",
      "@j_acquelines @CURRENTMOODio @oneouncegold @NguyenCoffeeNYC ğŸ¾ğŸ¾ğŸ¾\n",
      "@LouisPeitzman @SamuelAAdams More seat 4s for me!\n",
      "@SamuelAAdams Itâ€™s just hair and headphone itâ€™s fine\n",
      "@SamuelAAdams 4 is by far the best! You can rest your head on the window and sink into a protective shell\n",
      "@birbigs @NewOneBway Consider yourself reminded (albeit 4 days early), Birbigs! Please tell us the joke! @birbigs\n",
      "2021 boutta be the move\n",
      "@DankwaBrooks Sure waa\n",
      "@ScarlettEHarris Oh dear!\n",
      "@thugpop she really ate that ğŸ˜©\n",
      "\"mind ya business, nigga. Tuck ya paper\"\n",
      "@asarians @CNN I literally said this is how you do it. Read what I said before taking a shot next time.\n",
      "@RotoGut Read that as â€œOBPâ€, pretty close\n",
      "Bring it on, 2020.\n",
      "@moorehn @andohehir @AndrewKirell @AndrewHusband @AndrewDesiderio They def will\n",
      "@Nixon_Corral The Carolinas donâ€™t count, but driving from Portland to a DQ parking lot in Vancouver WA for 20 minutes just to make a phone call and check off Washington does.\n",
      "@caitiedelaney Bring a bucket of water from home and set it free at the beach\n",
      "@moorehn @andohehir @AndrewKirell and @AndrewHusband and @AndrewDesiderio belong in here too\n",
      "Sup guys, this is Spooky and I am on my way to @nycnextlevel - Happy New Year everyone! I am not sure who we will see today but I am excited to bring in 2020 with another Next Level Battle Circuit. More info soon when we go live.\n",
      "Just saw Brittany Runs a Marathon. Thanks for making me ugly cry for the start of 2020, @jillianbell.\n",
      "@Vahn16 did you know that ihop's eggs are so good because they mix in PANCAKE BATTER\n",
      "that first nap of 2020 absolutely slapped\n",
      "Ryan Eggold didn't win any awards for his role as Tom Keen, but I loved him in that part more than most other TV roles.\n",
      "@Big5Army @Stelfreeze The curve of the helmet is where heâ€™s showing off. Itâ€™s so nice\n",
      "@Big5Army @Stelfreeze Jeez, those lines are beautiful\n",
      "@xackclaret @thebirdprince @ComicBook Now Zach just needs a Switch. The bias is strong ğŸ˜­\n",
      "Tom Keen went out like a fucking G and a half on @NBCTheBlacklist\n",
      "@NicoleSegniniS @DaniCHurtado_ Thank you my love! All is good now â¤ï¸\n",
      "@ITSDJFLOW Not future lol\n",
      "welcome to my third decade of being furious about that episode of Friends where Monica thinks that Chandler is sexually attracted to sharks.\n",
      "Idk if The Blacklist is my favorite series of the last decade but I rewatch it more than any other show\n",
      "@CNN This is how you do something nice for someone. Donâ€™t film it and post to social. Just do a good thing and be glad you did it. No socia props needed.\n",
      "@JackieKostek @Palms @KTNV This is wonderful. Happy New Year Jackie!\n",
      "@AbbyMCarney What a very specific ask\n",
      "@Kehlani â¤ï¸ sending luv bb\n",
      "Itâ€™s January and the sun has been setting since 10 am\n",
      "2020 is gonna be amazing. Why? My birthday and Christmas are on Fridays, and 4th of July and Halloween are on Saturdays. Thatâ€™s why!\n",
      "One actual human appears in this movie and itâ€™s a woman who throws a cat in the trash\n",
      "@gaepol Thanks!\n",
      "@__melbae What is that\n",
      "@alanalevinson The energy Iâ€™m trying to see!!!!!\n",
      "@NoelEWilliams ğŸ”¥ğŸ”¥ğŸ”¥\n",
      "@DaveDuFourNBA Is this a bit?\n",
      "not sure why DONâ€™T F*CK WITH CATS isnâ€™t just a straight up desktop (nonfiction) film. it would probably be more interesting, since itâ€™s sort of halfway there anyways.\n",
      "@amandamull For a long ride I go straight for 4\n",
      "@Nelala_ Thank you my love, sound sooo much better! â¤ï¸\n",
      "@bourtneyburton Thank you my love, hope 2020 is treating you well already! â¤ï¸\n",
      "@LiquidTLO It's our favorite breakfast place here. So so good.\n",
      "@JimLaPorta @TSpoonFeed @BrandyZadrozny @yashar @pamelacolloff @MollyJongFast Youâ€™re right, youâ€™re right. And you never, ever need to apologize to me â˜ºï¸ğŸ¦‹\n",
      "@Manny_Alicandro ...for five minutes! This lady was clearing out one group for the next one.\n",
      "@Taken_aBlack That Oscar Isaac photo! ğŸ˜\n",
      "@JamarrBrown #QuickPicsList cc: @MissBeaE\n",
      "@MargalitEwart Who dat in the corner ğŸ¤”ğŸ˜ğŸ˜\n",
      "@woahitsjuanito Iâ€™m just telling you as it is, fellow Aries ğŸ”¥ğŸ˜‰\n",
      "speediest recovery wins ready set go\n",
      "@divadfoz At least he was moving. And got better as game wore on. I love Tanguy  but starting to worry heâ€™s not built for this.\n",
      "@britnidlc it really is!!!\n",
      "@MikeDSykes Thought it was to stop Giannis crazy part is theyâ€™ll probably get to the conference finals regardless\n",
      "@conz Ha same, but it freaked me out at the time, band seemed unnerved by it\n",
      "i did that whole *drop chief keef - earned it at 11:56:47pm so the beat go off at midnight* and nobody got it\n",
      "Guardiola wanted a keeper who was good with his feet...\n",
      "@alec_sturm Happy New Year fam\n",
      "@PascalGibBN ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "@anne2themax ğŸ˜­ğŸ˜­ğŸ˜­\n",
      "@jonquilynhill JQ ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "@scumbelievable â€œMy ignorance is as valuable as your knowledgeâ€\n",
      "Just had my first petty thought of 2020. Happy New Year!\n",
      "@HTMLflowers Itâ€™s the bleakest the show got\n",
      "INTO THE DARK: MIDNIGHT KISS: Closet monster. Impressively nails the specificity of a particular kind of group of affluent white gay men who are not especially interesting, but who think theyâ€™re interesting by virtue of their gayness. Very post-marriage equality horror. B+\n",
      "@peteeee Tell all the people I went to high school with that youre sitting next to that I say hi\n",
      "@Grady ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ how is that even possible\n",
      "@violanorth Thanks homie!\n",
      "@kellykeegs You get me\n",
      "@kbport714 Thanks!\n",
      "@PulpCereal Email is in my bio (although Iâ€™m a bit behind bc of the holidays).\n",
      "Emotionally sabotage yourself by looping Taylor Swiftâ€™s â€œNew Yearâ€™s Dayâ€ all day challenge\n",
      "@ndresfm oh LES DIABOLIQUES is an amazing film\n",
      "There is enough room for everyone. The Fire Marshall lets us know when itâ€™s at maximum capacity. Allow people to be excited and give them the support that you may not have gotten when you started.\n",
      "Naturally there will be people who will get a quick fix and then stop working out but planning for their demise, just so you can be a gym snob, is low.\n",
      "Remember when you first started seriously working out and how hard it was? Remember feeling like you wanted to quit or not having peers to support you because you â€œjoined a cult?â€\n",
      "Itâ€™s a new year and, yes, gyms will be crowded but instead of expressing your disdain for the eager crowds, through elitist posts and memes, be a little more encouraging.\n",
      "Yâ€™all are telling me that a house fried this rice?!\n",
      "@SethDRothman HNY, Sir - looking forward to getting back in the saddle\n",
      "@rachsyme To finally write that proposal &amp; book ğŸ™\n",
      "@KristyPuchko @kimbermyers Instead of book club, supper club ğŸ½\n",
      "@PulpCereal We got to see it first!\n",
      "guess Iâ€™m watching INTO THE DARK: MIDNIGHT KISS.\n",
      "@WordToReece ğŸ˜‚ğŸ˜‚\n",
      "@kimbermyers @KristyPuchko Oh, I definitely need to learn this skill\n",
      "the energy Iâ€™m bringing into this decade is that of a 9V battery.\n",
      "should I get into BTS this year\n",
      "@oeste The LRG tee is too powerful.\n",
      "@KerrPoints Canâ€™t live south of our nationâ€™s capital ğŸ˜‚\n",
      "@WayneSisk1 You sound like me!\n",
      "@Skeeterstandup @FlappersComedy I love it there.\n",
      "@desertowl_13 Same.\n",
      "@DanielAshley13 Good food?\n",
      "@BitchieBootie Jelly new year! (Autocorrect but I'm keeping it)\n",
      "@PamHutch Thank you!\n",
      "@alissamarie @maddiewhittle I can also vouch for this. It's a great time\n",
      "@PamHutch Happy new year! I'm reading a book now and binge watching\n",
      "@InHollywoodland Happy new year!\n",
      "@Nomad313 Haha\n",
      "@jaclynf It felt very, very good to say this. ğŸ˜€\n",
      "@smallnartless you already are\n",
      "Aidy Bryant about to takeover with The Shrill\n",
      "#coys\n",
      "@bwayducks @JoshLamon @QueenLesli @MaxCrumm @TheLucasSteele @annharada @TheNatalieWeiss Yesssssss! See you next weekend at The Duke!\n",
      "AdemÃ¡s explica, a la luz de investigaciones acadÃ©micas por quÃ© los salvadoreÃ±os prefieron quedarse en los suburbios en lugar de #NYC.\n",
      "La informaciÃ³n histÃ³rica describe las etapas de la inmigraciÃ³n a #NuevaYork y cÃ³mo empiezan a revelarse los datos de los Centroamericanos en los siglos XIX y XX.\n",
      "Jerk chicken from 2019. God's plan\n",
      "But when the distinctions between groups are so fine and largely based on institutional or political alignment rather than intellectual tradition, the argument can end up quite absurd on its merits.\n",
      "These two functions are not so related as one might think. People in a tradition of thought have lived through a variety of different political circumstances and alignments, possibly mixing factions around quite dramatically.\n",
      "Many political ideologies are obsessed with niche labels but none, it seems to me, more so than libertarians. The mileage they apparently expect to get from gerrymandering some new label just so to include only those they agree with most is extraordinary.\n",
      "@sales_off_film @Flixwise â¤ï¸â¤ï¸â¤ï¸\n",
      "Pixar is making an isekai send tweet\n",
      "@KenParille Youâ€™re crazy for this one\n",
      "For*\n",
      "went to hell &amp; back last year . So grateful for the high notes but realistically dealt with so many low times. I pushed through despite the odds as I always do. ğŸ™ğŸ½  I learned that not everyone has the same heart as me. I thank God for seeing me through. So ready fo 2020ğŸ’š\n",
      "@WordToReece Migo canâ€™t wait to meet his cousin!\n",
      "@frynaomifry He loved the slither of a sexy lady snake\n",
      "Hereâ€™s to an end to white supremacist patriarchy and dismantling all the layers of bystanders that enable its bullshit. Happy New Year. ğŸ‰\n",
      "â€œYou realize,â€ I said, â€œthat your friend is the embodiment of white dude entitlement that represents everything thatâ€™s wrong with everything right now, right?â€  He laughed and said, â€œOh, heâ€™s not entitled, heâ€™s justâ€”â€œ\n",
      "(See aforementioned â€œwho knows what kind of dude this one isâ€ thought above.) He tried for a second more to convince us, and I decided to turn back to the friend, who was now talking to a woman.\n",
      "That grabs one of us?) and gathered our stuff to go.   His friend, decidedly more sober, came over and tried to explain that his friend was â€œcool.â€ I said, â€œHe is most certainly not â€˜cool.â€™â€ And I started to walk away.\n",
      "He said, â€œthatâ€™s ok.â€ He was sitting on our other friendâ€™s coat. I said, â€œDude. You gotta go.â€ He said, â€œehhnnnnnâ€ in his drunken slur. We were getting ready to go anyways, so, doing what women are trained to do, we avoided confrontation (would this be the one that swings at us?\n",
      "At the end of our usual delightful NYE night out (homie dinner + karaoke), a dude came up and plopped down in the seat, square in the middle of us, that had just been vacated by one of our people going over to the bathroom. I said, â€œDude, someoneâ€™s sitting there.â€\n",
      "@Millsy11374 Very here for this\n",
      "@ymercado @DanaSchwartzzz Only correct answer\n",
      "@DanaSchwartzzz Logan Marshall Greene\n",
      "Bring me this coat as if its an exquisite sacrifice\n",
      "rewatching THE HUDSUCKER PROXY (natch), and Tim Robbins is so adorable!!! So bright eyed and bushy tailed.\n",
      "@NoelMu Too cute! Happy New Year to you and the family. â¤ï¸\n",
      "@karenkho ğŸ˜\n",
      "@ActaBunniFooFoo Anytime dude!! We have to play Halo together some time :)\n",
      "@Chrissao_ Youâ€™re already a step ahead there. Talking about it is a great place to start and I have confidence that youâ€™ll achieve that goal!\n",
      "Rihanna Album/Fiona Album 2020\n",
      "Just remember guysâ€¦ itâ€™s 2020. We are lucky enough to have apps like @uber and @Lyft. Please, please, PLEASE donâ€™t drink and drive! Enjoy yourselves tonight, but please keep yourself (and others) safe!\n",
      "@colindickey Champagne saberer strikes again!ğŸ¥‚\n",
      "Whatâ€™s your New Years resolution?   For myself: I want to continue to focus on improving my commentary and hosting work. I also want to actually start getting serious about content creation.\n",
      "@KEBroady Sho ainâ€™t\n",
      "@gareth_vader @JupiterPirates Oh thank you. Would love to catch up with Farnay one day.\n",
      "@DaltonReed5 Sehr gut! Deutsch lernen macht SpaÃŸ â˜ºï¸\n",
      "new year, new attempt to correctly write the date on invoices and checks\n",
      "Welcome to 2020\n",
      "Oh and the 2019 Mideast peace deal rollout was a success. ×¢×•×“ × ×¦×—×•×Ÿ ×›×–×”...\n",
      "@KrisLovesMovies ğŸ’œğŸ’œğŸ’œğŸ’œ\n",
      "@MediaversityRev ğŸ˜‚ğŸ¤£\n",
      "@EriktheMovieman And to you as well! â˜ºï¸\n",
      "Happy Year That Cats Didnâ€™t Come Out\n",
      "@sundownmotel It certainly has the best scenes of war among the stars\n",
      "Happy new year! #2020NewYear\n",
      "And if you want to ensure itâ€™s an amazing one - go support @swingleft right now.\n",
      "Hot Girl â€˜20s\n",
      "@AcrossTheArch Canâ€™t wait to see you next week at The Duke!\n",
      "@xraylegend @SideshowGaming Felix AÃ±o to you too!!!\n",
      "Next New Years is either going to be amazing or absolutely horrific. There is no in between.   Have a happy 2020 all!\n",
      "@MykeCole You are the actual best.\n",
      "Happy new year, very thankful for all the sponsored content I integrated with this year\n",
      "Happy New Year to those who observe\n",
      "@sara_del sara same!!!!!!\n",
      "2019 was a great year, canâ€™t wait to see what 2020 has in store for us all. Happy New Years â¤ï¸\n",
      "DJ playing an aggressive Young Money set right now you have to respect it.\n",
      "YALL BEYONCE JUST POSTED A BLACK SQUARE WHAT DOES THIS MEANNNNNN\n",
      "Best decade of my life. Canâ€™t complain. Onwards and better. #Happy2020\n",
      "@sara_del ğŸ’œğŸ’œğŸ’œğŸ’œğŸ’œğŸ’œğŸ’œ\n",
      "2019 is probably the last year that America is a democracy. Anyway, yes, TELL HIM HOW YOU FEEL TONIGHT.\n",
      "@DPNash5 Heâ€™s always been...\n",
      "Wishing you all a happy, healthy, and prosperous #NewYear. Iâ€™m so thankful to all the amazing people in my life and canâ€™t wait to see what 2020 has in store for us!  ğŸ‰ğŸ’¥ğŸ‰ğŸ’¥ğŸ‰\n",
      "@Evanwithani @bonesrubo Should worst his ass imho\n",
      "In conclusion, 2019 was a year of contrasts. Thank you.\n",
      "@HayesBrown @pixiedei Awww! Congrats!\n",
      "@heathcummingssr ğŸ»\n",
      "@YardsPerGretch ğŸ»\n",
      "Wishing everyone a very happy new year!\n",
      "@StelliniTweets Sterling Hitchcock\n",
      "@sarahcave76 @BernieSanders ğŸ™ŒğŸ¼\n",
      "Throughout the decade, I think Iâ€™ve really embraced who I am &amp; what I wanna be.  Iâ€™m sorta really different now but also... more me. If that makes sense to you, I think weâ€™re doing it right.  âœŒğŸ»2010s\n",
      "@janetmock @EW @Beyonce @tyraaross @MjRodriguez7 @IndyaMoore happy new year ğŸ¦„ ğŸ‰ ğŸ˜˜\n",
      "@zzdoublezz YEP\n",
      "If you hit play on Irishman last Monday at noon, the final scene will end right as the clock strikes midnight. Start the new year off right\n",
      "@pwallinga The washest wash everything is a construct\n",
      "@Mercede73858625 Thank you\n",
      "@B0NNIE_ Bout to do the same in 2020.\n",
      "@bcsmith23 @jjscally_10 All the best for 2020, Brian - letâ€™s do that ğŸ™Œ\n",
      "@Jo_Unwin Ha yes, I have heard that one a few times in the last 34! Happy mutual bday, Jo ğŸˆ\n",
      "@JLa_NYC Thanks Jenny ğŸ™\n",
      "@ideserveabeer ğŸ¤™\n",
      "@NYisBLUE Thank you my man, all the best to you and yours in 2020\n",
      "In fear of sounding hipsterish, crazy to think I've listened to @Skrillex consistently throughout the entire decade.  Remember a friend showing me \"My Name is Skrillex\" at my grandmother's house in 2010 and having good memories to \"Bangarang EP\" and \"Recess.\"\n",
      "@linzsports Just saying I think this year will be notable even compared to past precedent\n",
      "@linzsports Thatâ€™s for sure\n",
      "@John_Hong Trying to theme my months, also tying a different exercise routine to each month\n",
      "@Kbald77 Letâ€™s gooooooo\n",
      "@Politisite Iâ€™m still partying like itâ€™s 1999.\n",
      "Is this...fan fiction??\n",
      "As a queer person of color, I will reiterate what Iâ€™ve said before: The only moral approach to 2020 is â€œHope for the best; expect the worst.â€ Fight your battles accordingly. But do fight them.\n",
      "@akidos Dude congratulations on getting married!!!! ğŸ˜\n",
      "got a blister from playing videos games for 5 days straight\n",
      "@danieltkelley @lauriegale210 What a glow up ğŸ™Œ\n",
      "@josephpallant Decade made :)\n",
      "@gletham Trur. It says a lot about the state of things and even more about the what CES thinks about women &amp; the industry.\n",
      "@YoAdriBaby ğŸ™ğŸ»ğŸ™ğŸ»ğŸ™ğŸ»\n",
      "@hanwong LOL number one in my heart!\n",
      "@antbluejr ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\n",
      "@thegnc You are freaking great.\n",
      "@josephpallant You are a good human.\n",
      "@LaDeziree â¤ï¸â¤ï¸â¤ï¸â¤ï¸\n",
      "@zayasman Gracias! Thank you for the good wishes. Hope you have a wonderful NYE y AÃ±o Nuevo! â˜ºï¸\n",
      "Best songs lists are impossible, because there are like 140 top-10 songs from this decade, but those are the ones that game up from a quick perusal of my record collection and playlists.   Itâ€™s a perfect list.\n",
      "Go ahead and add â€œA More Perfect Unionâ€ by Titus Andronicus, â€œHannah Huntâ€ by Vampire Weekend, â€œPaulâ€ by Big Thief,â€ and â€œElevator Operatorâ€ by Courtney Barnett and weâ€™ll call it a top-10\n",
      "@HappytobeDee Sounds like a WHOLE plan!!\n",
      "Best songs of the 2010s, off the top of the old dome  1. Night Shift - Lucy Dacus  2. All Too Well - Taylor Swift 3. Me and My Dog - boygenius 4. Old Friends - Pinegrove 5. Ultralight Beam - Kanye West ft. Chance the Rapper  6. Your Best American Girl - Mitski\n",
      "@LenoreMariee ğŸ¥° so so proud of YOU!\n",
      "@jorgevalens I thought you would like that one\n",
      "@Eugene_Scott ğŸ™„\n",
      "@ERodriguez782 Ha, totally get it.Happy New Year to you.\n",
      "Moana was the best Disney movie of the decade, and Iâ€™m including everything in their IP portfolio\n",
      "happy bday to my fav fellow canadian @smrtdeath\n",
      "@DippyNikki My goodness that's impressive\n"
     ]
    }
   ],
   "source": [
    "result,cnt0,cnt1 = allInOne('Brooklyn_Week1.csv')\n",
    "nyc = pd.read_csv('Brooklyn_Week1.csv')\n",
    "for i in range(0,len(result)):\n",
    "    if(result[i]==1):\n",
    "        print(nyc['tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2018-01-01\n2018-01-08\n2018-01-15\n2018-01-22\n2018-01-29\n2018-02-05\n2018-02-12\n2018-02-19\n2018-02-26\n2018-03-05\n2018-03-12\n2018-03-19\n2018-03-26\n2018-04-02\n2018-04-09\n2018-04-16\n2018-04-23\n2018-04-30\n2018-05-07\n2018-05-14\n2018-05-21\n2018-05-28\n2018-06-04\n2018-06-11\n2018-06-18\n2018-06-25\n2018-07-02\n2018-07-09\n2018-07-16\n2018-07-23\n2018-07-30\n2018-08-06\n2018-08-13\n2018-08-20\n2018-08-27\n2018-09-03\n2018-09-10\n2018-09-17\n2018-09-24\n2018-10-01\n2018-10-08\n2018-10-15\n2018-10-22\n2018-10-29\n2018-11-05\n2018-11-12\n2018-11-19\n2018-11-26\n2018-12-03\n2018-12-10\n2018-12-17\n2018-12-24\n2018-12-31\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    " \n",
    "year = 2018\n",
    "date_object = date(year, 1, 1)\n",
    "date_object += timedelta(days=1-date_object.isoweekday())\n",
    " \n",
    "while date_object.year == year:\n",
    "    print(date_object)\n",
    "    date_object += timedelta(days=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                            is so sad for my APL frie...\n",
       "1                          I missed the New Moon trail...\n",
       "2                 .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "3                i think mi bf is cheating on me!!!   ...\n",
       "4                       or i just worry too much?        \n",
       "                              ...                        \n",
       "5282     waiting for claire to leave to glendale for t...\n",
       "5283     wanna do some sessions with ronnie he da bomb...\n",
       "5284          want my new mac! I'm getting impatient now!\n",
       "5285     wanted to see a Laker/Cav match-up. Oh well G...\n",
       "5286     wants to go on Ajax Experience 2009 http://bi...\n",
       "Name: tweet, Length: 5287, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sadData.csv')\n",
    "df.loc[:,'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "this week  5287 tweets collected in TimeSquare\nSad rate is 0.834909228441755\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0, 0, 0, ..., 0, 0, 0]), 4415, 0.834909228441755]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "from string import punctuation\n",
    "import preprocessor as p\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "def preprocess(fileName):\n",
    "    nyc = pd.read_csv(fileName, encoding='ISO-8859-1')\n",
    "    for i in range(0, len(nyc)):\n",
    "        nyc.loc[:, 'tweet'][i] = p.clean(nyc.loc[:, 'tweet'][i])\n",
    "        nyc.loc[:, 'tweet'][i] = ''.join(\n",
    "            [c for c in nyc.loc[:, 'tweet'][i] if c not in punctuation])\n",
    "        nyc.loc[:, 'tweet'][i] = nyc.loc[:, 'tweet'][i].lower()\n",
    "    return nyc\n",
    "\n",
    "\n",
    "def predict(dataFrame, vec, lrModel):\n",
    "    nyc = dataFrame\n",
    "    tweet = vec.transform(nyc.loc[:, 'tweet'])\n",
    "    predict = lrModel.predict(tweet)\n",
    "    cnt0 = 0  # negative\n",
    "    cnt1 = 0  # positive\n",
    "    for i in range(0, len(nyc)):\n",
    "        if(predict[i] == 0):\n",
    "            cnt0 += 1\n",
    "        else:\n",
    "            cnt1 += 1\n",
    "    print(\"this week \", len(nyc), \"tweets collected in TimeSquare\")\n",
    "    sad_rate = cnt0/(len(nyc)+1)\n",
    "    print(\"Sad rate is\", sad_rate)\n",
    "    return [predict, cnt0, sad_rate]\n",
    "\n",
    "\n",
    "def allInOne(fileName):\n",
    "    nyc = preprocess(fileName)\n",
    "    lrModel = joblib.load('saved_model/lr.pkl')\n",
    "    vec = joblib.load('saved_model/vec.pkl')\n",
    "    print(nyc)\n",
    "    result = predict(nyc, vec, lrModel)\n",
    "\n",
    "    return result\n",
    "\n",
    "allInOne('sadData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}