{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 逻辑回归完成二分类，利用sklearn库完成tokenize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @ when a father is dysfunctional and is so se...\n",
       "1   2      0  @ @ thanks for #lyft credit i can't use cause ...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@ when a father is dysfunctional and is so se...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@ @ thanks for #lyft credit i can't use cause ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "# tweet = df.iloc[:,-1]\n",
    "# label = df.iloc[:,1]\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "### 数据清洗"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tweet-preprocessor to clean tweets\n",
    "from string import punctuation\n",
    "import preprocessor as p\n",
    "for i in range(0,len(df)):\n",
    "    df['tweet'][i] = ''.join([c for c in df['tweet'][i] if c not in punctuation])\n",
    "    df['tweet'][i] = p.clean(df['tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  when a father is dysfunctional and is so selfi...\n",
       "1   2      0  thanks for lyft credit i cant use cause they d...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0      model i love u take with u all the time in ur\n",
       "4   5      0                  factsguide society now motivation"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>when a father is dysfunctional and is so selfi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>thanks for lyft credit i cant use cause they d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>model i love u take with u all the time in ur</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide society now motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['tweet'], df['label'], test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression to classify\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "predicted = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification report for classifier LogisticRegression():\n              precision    recall  f1-score   support\n\n           0       0.96      0.99      0.98      8908\n           1       0.85      0.47      0.61       681\n\n    accuracy                           0.96      9589\n   macro avg       0.91      0.73      0.79      9589\nweighted avg       0.95      0.96      0.95      9589\n\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (lr, classification_report(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLrModel():\n",
    "    df = pd.read_csv('trainNew.csv')\n",
    "    df.head()\n",
    "\n",
    "    for i in range(0,len(df)):\n",
    "        df['tweet'][i] = ''.join([c for c in df['tweet'][i] if c not in punctuation])\n",
    "        df['tweet'][i] = p.clean(df['tweet'][i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['tweet'], df['label'], test_size=0.3, shuffle=False)\n",
    "\n",
    "    vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "\n",
    "    return [vectorizer,lr]"
   ]
  },
  {
   "source": [
    "## 对于爬虫数据集进行处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id      conversation_id               created_at  \\\n",
       "0  1347332013104246785  1347332013104246785  2021-01-08 07:59:18 CST   \n",
       "1  1347330120529412100  1347330120529412100  2021-01-08 07:51:47 CST   \n",
       "2  1347326991691894785  1347326991691894785  2021-01-08 07:39:21 CST   \n",
       "3  1347326056160763904  1347326056160763904  2021-01-08 07:35:38 CST   \n",
       "4  1347324286902689792  1347324286902689792  2021-01-08 07:28:36 CST   \n",
       "\n",
       "         date      time  timezone              user_id   username  \\\n",
       "0  2021-01-08  07:59:18       800             40357519    tjsalon   \n",
       "1  2021-01-08  07:51:47       800  1030110827154743297  glenn_biz   \n",
       "2  2021-01-08  07:39:21       800            487187356    evauseb   \n",
       "3  2021-01-08  07:35:38       800             50706690      511ny   \n",
       "4  2021-01-08  07:28:36       800             50706690      511ny   \n",
       "\n",
       "                                        name  \\\n",
       "0                       Timothy John's Salon   \n",
       "1                                 Kurt Glenn   \n",
       "2  cardi b, jt, and meg areola stan account.   \n",
       "3                               511 New York   \n",
       "4                               511 New York   \n",
       "\n",
       "                                               place  ...  \\\n",
       "0  {'type': 'Point', 'coordinates': [40.76459, -7...  ...   \n",
       "1                                                NaN  ...   \n",
       "2                                                NaN  ...   \n",
       "3  {'type': 'Point', 'coordinates': [40.752998, -...  ...   \n",
       "4  {'type': 'Point', 'coordinates': [40.762456, -...  ...   \n",
       "\n",
       "                     geo source user_rt_id user_rt retweet_id  reply_to  \\\n",
       "0  40.75773,-73.9857,1km    NaN        NaN     NaN        NaN        []   \n",
       "1  40.75773,-73.9857,1km    NaN        NaN     NaN        NaN        []   \n",
       "2  40.75773,-73.9857,1km    NaN        NaN     NaN        NaN        []   \n",
       "3  40.75773,-73.9857,1km    NaN        NaN     NaN        NaN        []   \n",
       "4  40.75773,-73.9857,1km    NaN        NaN     NaN        NaN        []   \n",
       "\n",
       "   retweet_date  translate trans_src trans_dest  \n",
       "0           NaN        NaN       NaN        NaN  \n",
       "1           NaN        NaN       NaN        NaN  \n",
       "2           NaN        NaN       NaN        NaN  \n",
       "3           NaN        NaN       NaN        NaN  \n",
       "4           NaN        NaN       NaN        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>conversation_id</th>\n      <th>created_at</th>\n      <th>date</th>\n      <th>time</th>\n      <th>timezone</th>\n      <th>user_id</th>\n      <th>username</th>\n      <th>name</th>\n      <th>place</th>\n      <th>...</th>\n      <th>geo</th>\n      <th>source</th>\n      <th>user_rt_id</th>\n      <th>user_rt</th>\n      <th>retweet_id</th>\n      <th>reply_to</th>\n      <th>retweet_date</th>\n      <th>translate</th>\n      <th>trans_src</th>\n      <th>trans_dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1347332013104246785</td>\n      <td>1347332013104246785</td>\n      <td>2021-01-08 07:59:18 CST</td>\n      <td>2021-01-08</td>\n      <td>07:59:18</td>\n      <td>800</td>\n      <td>40357519</td>\n      <td>tjsalon</td>\n      <td>Timothy John's Salon</td>\n      <td>{'type': 'Point', 'coordinates': [40.76459, -7...</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,1km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1347330120529412100</td>\n      <td>1347330120529412100</td>\n      <td>2021-01-08 07:51:47 CST</td>\n      <td>2021-01-08</td>\n      <td>07:51:47</td>\n      <td>800</td>\n      <td>1030110827154743297</td>\n      <td>glenn_biz</td>\n      <td>Kurt Glenn</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,1km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1347326991691894785</td>\n      <td>1347326991691894785</td>\n      <td>2021-01-08 07:39:21 CST</td>\n      <td>2021-01-08</td>\n      <td>07:39:21</td>\n      <td>800</td>\n      <td>487187356</td>\n      <td>evauseb</td>\n      <td>cardi b, jt, and meg areola stan account.</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,1km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1347326056160763904</td>\n      <td>1347326056160763904</td>\n      <td>2021-01-08 07:35:38 CST</td>\n      <td>2021-01-08</td>\n      <td>07:35:38</td>\n      <td>800</td>\n      <td>50706690</td>\n      <td>511ny</td>\n      <td>511 New York</td>\n      <td>{'type': 'Point', 'coordinates': [40.752998, -...</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,1km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1347324286902689792</td>\n      <td>1347324286902689792</td>\n      <td>2021-01-08 07:28:36 CST</td>\n      <td>2021-01-08</td>\n      <td>07:28:36</td>\n      <td>800</td>\n      <td>50706690</td>\n      <td>511ny</td>\n      <td>511 New York</td>\n      <td>{'type': 'Point', 'coordinates': [40.762456, -...</td>\n      <td>...</td>\n      <td>40.75773,-73.9857,1km</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "nyc = pd.read_csv('NewYork.csv')\n",
    "nyc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import preprocessor as p\n",
    "for i in range(0,len(nyc)):\n",
    "    nyc['tweet'][i] = ''.join([c for c in nyc['tweet'][i] if c not in punctuation])\n",
    "    nyc['tweet'][i] = p.clean(nyc['tweet'][i])\n",
    "\n",
    "vec,lrModel = getLrModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = vec.transform(nyc['tweet'])\n",
    "predict = lrModel.predict(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looks like a scene from the movie Scarface but no its our Capitol of the UnitedStates this is Maga not blacklivesmatter Capitol at Washington DC httpstcoCiGnywsax7\n\nIBM is looking for teammates like you See our latest Marketing job openings including Client Solution Executive Business Process Outsourcing BPO via the link in our bio NewYork NY\n\nMedcor is hiring in NewYork NY Read about our latest HealthWelfare job opening via the link in our bio COVID Compliance Officer RN NY amp NJ\n\nSpeaking for the Cannoli who have no voice We do not accept your labels or comparisons Be Kind Drink Espresso equality Wall Street Bull New York httpstcoNJQ57z1tlp\n\nHave you ever had a role like Associate Partner Financial Services What did you like most about that job Banking NewYork NY\n\noptimism by the Dapper Don berzinsky Theres just something about a draped bow tie in black and white by normallyaspirated scbocaraton happynewyear blacktie Rockafeller Center In Manhattan httpstcoYyGphuaNrM\n\nI hope the NewYear2021 would bring back normalcy and keep everyone safe and the problems of would fade away WrapUp2020 GoodBye2020 Welcome2021 httpstcoxb3DsIWOaw\n\nI explore how businesses are affected by the lack of a crowd in TimesSquareNYC this year on NYE amp how a new app can connect you to this years celebration newyearseve timessquare nyc nywx happynewyear httpstcodVzh9teA4N\n\nSee our latest New York NY job and click to apply COVID Compliance Officer RN NY amp NJ httpstcoyVGyxCve8D OccupationalHealth Triage\n\nmmpadellan fcuking White Terrorists Ihave sworn to uphold and defend the Constitution against all enemies foreign and domestic and I will come to peace with myself my God and my cause Blood will flow in the streets Good vs Evil Free men vs Socialist Wannabe Slaves Timothy McVeigh httpstcomErVP8MjVo\n\nJimJordan Be careful Mr Gym Jordan You are bitting the hand that feeds you You should be bitting Trumps hand not the Government Dont forget that you are one of the biggest reptiles of the SWAMP httpstcoNnwNavk4WP\n\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(nyc['tweet'])):\n",
    "    if(predict[i]==1):\n",
    "        print(nyc['tweet'][i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}